{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70fbd319-7dee-4fca-8c51-b425e84d858f",
   "metadata": {},
   "source": [
    "# Part 2 - Custom Testset Walkthrough\n",
    "This notebook contains blocks to guide you through how to create your own test set and evaluate the pre-trained models with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Import the git repo and install required libraries\n",
    "!git clone --branch Showcase https://github.com/Hapemo/Deepfake-Audio-Detection/\n",
    "%cd Deepfake-Audio-Detection/\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Prepare data folder and download speech samples\n",
    "!mkdir data\n",
    "%cd data\n",
    "!gdown 1WevCjrJJ7pv9XzCwjbyJ1iNr2uoOYnZI\n",
    "!gdown 1TE88aXpA5YvTP5KwjM_1SYs3_HinXjDj\n",
    "!gdown 1JvitJbYdjojw5ORYv42XTA9iairs8_40\n",
    "!unzip showcase_samples.zip\n",
    "!unzip SileroVAD_samples.zip\n",
    "!unzip SPEAKER0001.zip\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf844a",
   "metadata": {},
   "source": [
    "## Preparing your testset\n",
    "There are 2 things to take note when you are making the dataset, the file type and naming convention.\n",
    "\n",
    "First and simplest, the file type has to be .wav file\n",
    "\n",
    "The naming convention is a little more complex. To make things simple, during training and evaluation, the model determines that a speech is spoofed if the naming of the file without extension is more than 8 characters. Eg, 12345678.wav is deemed bonafide and 123456789.wav is deemed spoof.\n",
    "\n",
    "To use your own dataset, you will need to exercise your python skills a little to change the names to fit the testing ground. The 'os' module will be useful for managing path and the 'shutil' module will be useful for renaming the file. Below are some tips for your custom file names.\n",
    "\n",
    "1. Using alphabet on any filename will ensure the naming will not clash with sample audio provided, because sample audio file name only contains number and '-'.\n",
    "2. Please make sure your audio file extension is '.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b588e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small code segment to demonstrate how to convert the files to suitable naming convention and 'wav' files. \n",
    "%pip install pydub # Comment this out when it's installed already\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "srcdir = \"source directory of speech to convert\"\n",
    "dstdir = \"final dircetory of speech converted\"\n",
    "counter = 0\n",
    "spoof = False # Remember to change this!\n",
    "\n",
    "if not os.path.exists(dstdir): os.makedirs(dstdir)\n",
    "\n",
    "def nestLooper(dir: str, func):\n",
    "    ''' Loop through all the files in the directory and sub directories, and apply a function on it '''\n",
    "    for file in os.listdir(dir):\n",
    "        nestedDir = os.path.join(dir, file)\n",
    "        if os.path.isdir(nestedDir): nestLooper(nestedDir, func)\n",
    "        func(nestedDir)\n",
    "\n",
    "def mp3FileNamer(filepath:str):\n",
    "    ''' Generate an unique name for speech file, convert mp3 file into wav and save it '''\n",
    "    extension = filepath.split('.')[-1]\n",
    "    \n",
    "    if extension != 'mp3' and extension != 'wav': return\n",
    "\n",
    "    global counter\n",
    "    if spoof:\n",
    "        newbasename = f\"s{str(counter).zfill(10)}.wav\"\n",
    "    else:\n",
    "        newbasename = f\"b{str(counter).zfill(7)}.wav\"\n",
    "    counter += 1\n",
    "\n",
    "    if extension == \"mp3\":\n",
    "        sound = AudioSegment.from_mp3(filepath)\n",
    "        sound.export(os.path.join(dstdir, newbasename), format=\"wav\")\n",
    "    else:\n",
    "        shutil.copy(filepath, os.path.join(dstdir, newbasename))\n",
    "    print(f\"Converted {filepath} to {os.path.join(dstdir, newbasename)}\")\n",
    "\n",
    "nestLooper(srcdir, mp3FileNamer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a4984",
   "metadata": {},
   "source": [
    "## Prepare your config file for dataset\n",
    "The config file dictates which pretrained model, what model parameters, what hyperparameters, and what dataset to use. For this section, the focus will be on custom dataset, you wil need to take note of 6 settings in the config file.\n",
    "1. database_path\n",
    "    \n",
    "    database path indicates the relative path of the database\n",
    "2. use_new_fileloader\n",
    "    \n",
    "    Since the original AASIST codebase have their own dataloading method that is unsuitable for our usage, the value of this must be 1, to ensure it uses our custom dataloading method.\n",
    "3. blacklist_folders, eval_folders, dev_folders, train_folders\n",
    "    \n",
    "    To explain how to configure this, we have to first introduce the loading structure. All the files and folders residing in database_path will be scanned, all nested folders and nested files. blacklist_folders indicates the folders that will be ignored when collecting data. eval_folders indicates the folders AND all their nested folders will be scanned for wav file, adding all scanned wav files to eval dataset. Same for dev_folders and train_folders. \n",
    "    \n",
    "    After scanning, there will be a segmented_info.txt generated, containing information of data path and the dataset they belong to. This file will be created at the database_path. When you want to run a new dataset config, delete this text file, if not the model will just run the old dataset config to save time.\n",
    "\n",
    "### Example\n",
    "This is the folder structure\n",
    "\n",
    "<pre>└── dataset_root/\n",
    "   ├── data1/\n",
    "   │   ├── eval_1/\n",
    "   │   │   ├── eval1.1\n",
    "   │   │   └── eval1.2\n",
    "   │   ├── dev_1/\n",
    "   │   │   ├── dev1.1\n",
    "   │   │   └── dev1.2\n",
    "   │   └── train\n",
    "   ├── data2/\n",
    "   │   ├── eval_2/\n",
    "   │   │   ├── eval2.1\n",
    "   │   │   └── eval2.2\n",
    "   │   └── dev_train_2/\n",
    "   │       ├── data2_dev\n",
    "   │       └── \n",
    "   └── data3/\n",
    "       ├── eval_1/\n",
    "       │\n",
    "       └── dev_train\n",
    "\n",
    "\"database_path\": \"dataset_root\",\n",
    "\"blacklist_folders\": \"data3\",\n",
    "\"eval_folders\": \"eval_1, eval_2\",\n",
    "\"dev_folders\": \"dev_1, data2_dev\",\n",
    "\"train_folders\": \"train, dev_train_2\",\n",
    "\"use_new_fileloader\": 1\n",
    "\n",
    "</pre>\n",
    "Final dataset will contain data from these folders,\n",
    "- Eval Set: eval1.1, eval1.2, eval2.1, eval2.2\n",
    "- Dev Set: dev1.1, dev1.2, data2_dev\n",
    "- Train Set: train, data2_train\n",
    "\n",
    "NOTE!\n",
    "- All the dataset must contain at least one data, thus SPEAKER0001 (dummy data) was added in some of the config file's train and dev set to fulfill this requirement. \n",
    "- There must be at least one bonafide and one spoof data in eval dataset during testing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5596bcb",
   "metadata": {},
   "source": [
    "## Running evaluation\n",
    "Navigate to the base directory of the repository, change the config file below and ensure there is '--eval' flag\n",
    "\n",
    "The EER for the following config should be as follows:\n",
    "- Apple1.1.config: 0.14065%\n",
    "- Apple1.2.config: 1.54716%\n",
    "- AASIST.config: 16.80744%\n",
    "\n",
    "### Details about the pretrained models and evaluation dataset\n",
    "AASIST model is trained on the ASV2019 dataset, comprising of english spoken speeches with western accent. They spoofed speeches are generated from wide range of audio formats, Text-To-Speech and Voice Conversion models. \n",
    "\n",
    "Apple1.1 model is trained on all the dataset in AASIST model, plus bonafide english speeches with singaporean accent and their spoofed counterparts. The spoofed counter parts are generated with Mangio-RVC and wide range of TTS like Coqui, FastSpeech2 and StyleTTS2\n",
    "\n",
    "Apple1.2 model is trained on all the dataset in Apple1.1. Except, the Singaporean accent bonafide and spoofed data went through audio trimming via ML model SileroVAD to remove non-speech portions in the audio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"pyfiles/main.py\" --eval --config \"./config/Apple1.1.conf\" \n",
    "%run \"pyfiles/main.py\" --eval --config \"./config/Apple1.2.conf\"\n",
    "%run \"pyfiles/main.py\" --eval --config \"./config/AASIST.conf\"\n",
    "# Remove segment_info.txt to refresh new dataset. \n",
    "# We only remove after these 3 config files because they are using the same evaluation dataset\n",
    "os.remove(\"data/segment_info.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48529ade",
   "metadata": {},
   "source": [
    "### Testing on SileroVAD speeches\n",
    "The EER result with Apple1.1 should be 33.33%, and for Apple1.2, it should be 0%.\n",
    "\n",
    "Why does Apple1.2 perform way better than Apple1.1?\n",
    "\n",
    "Try out these pretrained models on your custom evaluation dataset and see which one has the highest EER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f067952",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"pyfiles/main.py\" --eval --config \"./config/Apple1.1_eval_on_SileroVAD.conf\"\n",
    "%run \"pyfiles/main.py\" --eval --config \"./config/Apple1.2_eval_on_SileroVAD.conf\"\n",
    "# Remove segment_info.txt to refresh new dataset\n",
    "os.remove(\"data/segment_info.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
